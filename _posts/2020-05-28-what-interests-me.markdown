---
layout: post
title:  "What Interests Me Now"
date:   2020-05-28 19:33:00 -0500
categories: tech learning
author: Brian M. Hofmeister
---

If I'm being honest, at times the world of technology and software in particular can be overwhelming. It is difficult to comprehend, at times, how much has changed in tech over the past twenty five years or so. The internet in 1991, the year I started college, was still largely consistent of usenet, Gopher and a few other systems. The "web" was still a baby at the point, just a newly hatched thought experiment released to the wild that very year.

That said, the speed at which things are moving is exhilarating. The advance of mobile devices, streaming media, and the "internet of things (IoT)" are a beacon of the future. It's exciting. Staying current with technological trends is not always easy. Many software developers I know have limited exposure to different programming languages and environments. Some experiment on their own and venture into new areas for fun, but a good number are satisfied to let their work be what it is and their time outside of work is focused on other things. That's great for them, but for me there's a constant desire to try to learn something new, something interesting and different. I like to expose myself to different ways of thinking, and different solutions to the same problems.

### Trends in software development

There are three major trends I see that are very interesting to me, and at the same time remind me of the saying "what was once old is new again." 

First the obvious, cloud computing and IoT. In the dawn of the computer age, the technology was massively expensive and specialized. The advent of mainframe computers brought on time share computing which to me was really just cloud computing for that era. As the technology got cheaper and smaller, it made perfect sense that there was a shift toward localized computing power. The applications in those days were very much designed to support manual business processes. They were for reporting and data storage more than anything else. As the needs of applications evolved and the network became more and more important, the distribution of computing assets brought on new challenges for business in terms of management, administration, architecture, maintenance, and resilience. Cheaper and cheaper processing power and storage hardware and more and more network bandwidth created a sort of perfect storm for the client-server computing model to just fall apart. To be clear, I know cloud computing is definitely not the same thing as the mainframe computing of years ago. What is the same is that the way we now access computing resources is similar to the old time sharing model. Cloud services are typically priced according to use, or subscription based and paid for according to number of users. The shift to cloud was not driven entirely by the technology shifts, the economic models shifted as well. Consider also the fact that in the 60s and 70s, IBM dominated the hardware market. Today we have a few major players providing the vast majority of computing resources (thanks to commodity hardware that drives economies of scale) to power the billions and billions of devices coming online. The internet of things is, when considered carefully, just a further miniaturization of client/server computing; it's not really new at all, but it is a massive change in scale and reach.

A second trend that I have become particularly interested in is the return to the static web. This trend has even been given a name, the [JAMstack](https://jamstack.org/). The reasons for the success of the web are many. One indisputable reason it exploded was because it is an extraordinarily effective way of distributing information that is static. The fact that we have circled back from a web of dynamically generated and massively distributed software platforms toward a web that simplifies scalability and reduces dynamic content, on the surface is astonishing. Under the covers, however, it seems to me very logical, again given what has happened with technology in the past decade. Cloud services have made global scalability a common objective in software systems, it is no longer a wish list item. Those same cloud services have made access to data, at scale, much more straightforward. What was all that dynamic content on the web really about for all those years? Data. That's it. We invented some really complex and sometimes mind bending techniques to put data on web pages. The JAMstack, which simply refers to JavaScript, APIs, and markup, is really about putting the complexity genie back in the bottle. It's so simple, it feels like it should have been obvious years and years ago. Maybe to some it was. In the JAMstack, JavaScript and Markup are the front-end and APIs are really the back-end. Static pages and assets (including JS and CSS, images, fonts, etc) are generated and deployed as atomic application units. They can be massively distributed on content delivery networks (CDNs) and many of the issues of scaling go away. Users get a huge benefit of being able to access a site closest to their location, the site is delivered statically and page loads are generally much faster, typically with the data already present on the origin node, placed there at deploy time. The application can load any new or changed data since the last deploy via API calls. In a number of use cases, data changes actually trigger a redeploy of the application contents, and there is zero dynamic content ever necessary. This very *site* is being built with JAMstack techniques.

A third and final trend I am keenly interested in as a developer is the increasing popularity of functional programming (FP). There are hundreds of programming languages, a fact that is not particularly surprising. An increasing number of, increasingly popular, programming languages are placing greater emphasis on features supporting the functional programming paradigm. FP isn't new, either. Its origins stem back to the 1970s. I believe, however, that again this increasing interest in something that is old is mostly due to other shifts in technology and the economics of software. Our traditional methods of development, procedural and object-oriented software, have typically employed imperative style code. Over time, the complexity of imperative code increases, and without careful attention, eventually becomes very challenging to maintain. Declarative code, on the other hand, can be more straightforward to maintain, it exposes what the code is to do, not how it is done. Functional programming, in part, relies on a declarative style of programming. Furthermore, functional programming's requirements of immutability and no side effects, greatly reduce the presence of many typical sources of software defects, as well as allowing for increasing testing confidence and increasing degrees of parallel execution. With the demands of cloud computing, billions of devices coming online, an API driven software ecosystem, advances in multi-core processors, combined with the aging, increasingly brittle, difficult to test and difficult to understand legacy software systems, it really is not surprising that the software community is increasingly looking back in time at functional programming to help solve some of our challenges.

### What's the Mega-Trend?

Advances in software systems have, from early in the electronic computing age, been aimed at doing work more efficiently than humans. The earliest electronic computers were put to the test calculating necessary measures and mathematical models necessary to land the first men on the moon, and to return them safely to Earth. Today the goals of self-driving electric automobiles, artificial intelligence, even 3D printing and more are driving the same fundamental aims of computers doing work more efficiently than humans.

Those earliest systems were very specialized, doing one task and doing it repeatedly, without error. I think the overwhelming direction we are heading, ultimately, is back to that essential basic idea. Evidence that we are going that direction is already available in the form of serverless computing technologies and architectures, wherein entire systems are being assembled from single purposed, highly scalable, highly testable, functions provided as a service.